# Android Malware Detection Based on Parallel Machine Learning and Information Fusion
## 1. Xác định vấn đề
Cần xây dựng một mô hình học máy phân loại mã độc dựa trên dữ liệu đã được gán nhãn.

## 2. Dữ liệu đầu vào
Trong thử nghiệm này, chúng tôi đã chọn bộ dữ liệu phần mềm độc hại [CICMalDroid 2020](https://www.unb.ca/cic/datasets/maldroid-2020.html) do Đại học New Brunswick thu thập làm dữ liệu thử nghiệm. Bộ dữ liệu chứa 17.341 dữ liệu huấn luyện được gắn nhãn trải dài giữa năm danh mục riêng biệt: Adware, Banking malware, SMS malware, Riskware, và Benign(dữ liệu sạch). 

## 3. Thu thập dữ liệu
Để phân tích được dữ liệu thô này cần sử dụng đến công cụ [AndroPyTool](https://github.com/alexMyG/AndroPyTool) là một công cụ để trích xuất cả tính năng tĩnh và động từ các ứng dụng Android.Công cụ này tích hợp các công cụ phân tích ứng dụng Android nổi tiếng khác nhau như phân tích DroidBox, FlowDroid, Strace, AndroGuard hoặc VirusTotal. 
<details>
 <summary><b>Mục đích sử dụng công cụ AndroPyTool</b></summary>
 
-  Ứng dụng Android thường được viết bằng Java và thực thi trên Virtual Machine, byte code chạy trên Dalvik Virtual Machine (DVM) được chuyển đổi từ JVM byte code truyền thống sang dex-format(.dex file) bởi convertion tool dx.

-  Mã code thực thi trên DVM được gọi là mã Smali, có tập lệnh phức tạp giống như Assembly trên Windows. 

-  Việc phân tích các tệp smali để biết cách hoạt động của ứng dụng sẽ truy xuất được các Opcodes đã khai báo và các API call, Strings.

-  Mỗi dự án ứng dụng Android phải có một tệp AndroidManifest.xml. Tệp AndroidManifest.xml sẽ được phân tích thủ công thu được Permissions, Intents, Receivers, Services, Activities.
 
Tóm lại công cụ AndroPyTool giúp phân tích các file APK thành các tệp smali và phân tích thủ công file AndroidManifest.xml để trích xuất tính năng và tất cả thông tin được xử lý ở định dạng JSON.
#### JSON là gì?
JSON là chữ viết tắt của Javascript Object Notation, đây là một dạng dữ liệu tuân theo một quy luật nhất định mà hầu hết các ngôn ngữ lập trình hiện nay đều có thể đọc được, bạn có thể sử dụng lưu nó vào một file, một record trong CSDL rất dễ dàng.
#### Cấu trúc của JSON
Cấu trúc của JSON, được bắt đầu bằng kí tự `{` và kết thúc bằng kí tự `}`. Trong `{ ... }` sẽ định nghĩa những đối tượng.
#### JSON có liên quan gì đến Android
-  JSON là một kiểu mô tả dữ liệu được sử dụng phổ biến, nhiều công ty sử dụng JSON để gửi dữ liệu cho các ứng dụng Android, iOS hay WindowPhone.

-  Truyền dữ liệu: JSON (Ký hiệu đối tượng JavaScript) là định dạng dữ liệu nhẹ được sử dụng để trao đổi dữ liệu giữa máy chủ và máy khách. Đây là một định dạng phổ biến được sử dụng cho các dịch vụ web và API và các ứng dụng Android thường cần truy xuất dữ liệu từ các nguồn này.

-  Lưu trữ dữ liệu: JSON có thể được sử dụng để lưu trữ dữ liệu trong ứng dụng Android và có thể dễ dàng phân tích cú pháp để truy xuất dữ liệu. Điều này có thể hữu ích để lưu trữ dữ liệu cục bộ, chẳng hạn như tùy chọn người dùng hoặc cài đặt ứng dụng.

-  Dễ đọc và viết: JSON là định dạng mà con người có thể đọc được, giúp các nhà phát triển dễ dàng đọc và viết mã. Nó cũng cung cấp một cách đơn giản và nhất quán để biểu diễn dữ liệu, giúp làm việc và hiểu dễ dàng hơn.

-  Nền tảng độc lập: JSON độc lập với nền tảng, có nghĩa là nó có thể được sử dụng trong bất kỳ ngôn ngữ lập trình nào. Điều này khiến nó trở thành lựa chọn phổ biến cho các dịch vụ web và API cần hỗ trợ nhiều ngôn ngữ lập trình.

-  Truyền dữ liệu hiệu quả: JSON là một định dạng dữ liệu nhẹ, có nghĩa là nó có thể được truyền nhanh qua mạng, giúp giảm lượng dữ liệu cần truyền.

-  Nhìn chung, phân tích cú pháp JSON là một công cụ cần thiết cho các nhà phát triển Android, những người cần làm việc với dữ liệu từ các dịch vụ web và API hoặc lưu trữ dữ liệu cục bộ trong ứng dụng của họ.</details>

### 3.1. Giải thích các bước thực hiện
**Bước 1**: Lọc APK. Bước đầu tiên này chịu trách nhiệm kiểm tra từng mẫu bằng Androguard để kiểm tra xem mẫu đó có phải là ứng dụng Android đúng và hợp lệ hay không. 

**Bước 2:** Thực thi FlowDroid. Flow dựa trên phân tích vết bẩn. Khung Droid được thực thi cho từng mẫu. 

**Bước 3:** Xử lý đầu ra của FlowDroid. Đầu ra do FlowDroid cung cấp cho mỗi mẫu được xử lý để trích xuất các kết nối giữa các nguồn và bồn chứa được tìm thấy. 

**Bước 4:** Khai thác và xử lý đặc trưng. Cuối cùng, phần còn lại của các tính năng được trích xuất và tất cả thông tin được xử lý và xử lý để kết hợp với nhau. Báo cáo cho từng mẫu và đầu ra toàn cầu bao gồm tất cả các mẫu được phân tích được tạo ở định dạng JSON. 

### 3.2. Các bước thực hiện xử lý dữ liệu 
**Bước 1**: Sử dụng DOCKER CONTAINER \
Tiến hành cài đặt [Docker](https://docs.docker.com/desktop/install/windowsinstall/#:~:text=Double%2Dclick%20Docker%20Desktop%20Installer,bottom%20of%20your%20web%20browser.),
Docker Container đã có sẵn AndroPyTool nhanh và đáng tin cậy. Để sử dụng AndroPyTool bằng Docker chỉ cần mở Windows PowerShell thực thi các câu lệnh:
* Pull Andropytool 
```sh
$ docker pull alexmyg/andropytool
```
* Run AndroPyTool 
```sh
$ docker run --volume=</PATH/TO/FOLDER/WITH/APKS/>:/apks alexmyg/andropytool -s /apks/
```
Với “PATH/TO/FOLDER/WITH/APKS” là đường dẫn của thư mục chứa file mã độc. Đối số "-s" phải được cung cấp như được hiển thị trong dòng trên, trỏ tới /apks/. 

**Bước 2**: Vào container trong docker lấy DOCKER_IMAGE đưa DOCKER_IMAGE vào file "rundocker.py". Chạy rundocker.py để phân tích các file APK. 

## 4. Chuẩn bị dữ liệu
Như đã nói ở trên có thể ta có thể khai thác được rất nhiều tính năng và thông tin như API Call, Opcodes, Strings, Permissions, Intents,... Nhưng chúng ta sẽ tập trung vào opcodes vì chúng có liên quan chặt chẽ với mã ứng dụng.Thật vậy, một số công trình trong tài liệu đã chỉ ra rằng tần số opcode có thể phân biệt phần mềm phần mềm độc hại với phần mềm đáng tin cậy. Phân phối tần số opcodes của phần mềm độc hại lệch đáng kể so với các ứng dụng đáng tin cậy.Các chuỗi opcode có thể đại diện cho một loại chữ ký của phần mềm độc hại, luôn có sẵn và dễ dàng trích xuất từ ứng dụng cần phân tích.Hơn nữa, vì đây là một kỹ thuật tĩnh nên việc phân tích có ưu điểm là nhanh chóng và dễ thực hiện. 

Những bước chính bao gồm thu thập, làm sạch và ghi nhãn dữ liệu thô thành dạng thức phù hợp với các thuật toán máy học (ML), sau đó khám phá và trực quan hóa dữ liệu.
Bước đầu tiên cần làm là tách các giá trị và khóa trong các file JSON tham khảo trong [Extracting Specific Keys/Values From A Messed-Up JSON File (Python)](https://plainenglish.io/blog/extracting-specific-keys-values-from-a-messed-up-json-file-python-dfb671482681) song song với việc tách các giá trị và khóa ta thực hiện thêm bước gán nhãn sử dụng phương pháp [Label Encoding](https://www.geeksforgeeks.org/ml-label-encoding-of-datasets-in-python/) tương ứng với
| Name      | Label |
| :--------:|:-----:|
| Benign    | 0     |
| Adware    | 1     |
| Banking   | 2     |
| Riskware  | 3     |
| SMS       | 4     |

Xem source code trong file json handling.ipynb.
## 5. Khởi chạy hệ thống ML
[Convolutional Neural Networks in Python with Keras](https://www.datacamp.com/tutorial/convolutional-neural-networks-python)


```sh
# import data
import pandas as pd
import csv 
import os
DeepLearningFiletrain = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/DATA.csv')
DeepLearningFiletrain = DeepLearningFiletrain.drop(['file_name','lable'],axis=1)
DeepLearningFiletrain.to_csv(os.path.join('/content/drive/MyDrive/Colab Notebooks/DeepLearningFiletrain.csv'), index = False)
DeepLearningFiletrain = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/DeepLearningFiletrain.csv', skiprows=1, header=None)
```
```sh
#Feature Scaling
from sklearn.preprocessing import StandardScaler
sc = StandardScaler()
DeepLearningFiletrain = sc.fit_transform(DeepLearningFiletrain)
DeepLearningFiletrain = DeepLearningFiletrain.astype('float16')
df = pd.DataFrame(DeepLearningFiletrain)
df.to_csv('/content/drive/MyDrive/Colab Notebooks/DeepLearningFiletrain.csv', index = False)
```
```sh
#Importing the dataset
dataset = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/DeepLearningFiletrain.csv')
X = dataset.iloc[:, 1:]
dataset1 = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/DATA.csv')
y = dataset1.iloc[:, -1]
```
```sh
#Splitting the dataset into the Training set, Test set and Validation set
from sklearn.model_selection import train_test_split
train_X, X_test, train_Y, Y_test = train_test_split(X, y, test_size = 0.1, random_state = 0)

X_train, X_valid, Y_train, Y_valid = train_test_split(train_X, train_Y, test_size = 0.2, random_state = 0)
```
```sh
#Train the Model
from tensorflow.keras.utils import to_categorical
SIZE = (len(X_train.columns))
BATCH_SIZE = 32
SIZE2= 1
N_CLASSES = 256
LR = 0.001
N_EPOCHS = 30

X_train = X_train.values.reshape(X_train.shape[0], SIZE, SIZE2, 1)
Y_train = to_categorical(Y_train, N_CLASSES)
X_valid = X_valid.values.reshape(X_valid.shape[0], SIZE, SIZE2, 1)
Y_valid = to_categorical(Y_valid, N_CLASSES)
```
```sh
import keras
from keras.layers import Input
from keras.models import Sequential
from keras.layers import Dense
from keras.layers import Flatten
from keras.layers.convolutional import Conv2D
from keras.layers.pooling import MaxPooling2D
from keras.layers import concatenate
fashion_model = Sequential()

fashion_model.add(Input(shape=(SIZE,SIZE2,1)))
fashion_model.add(Conv2D(32, kernel_size=2, activation='relu', padding="same" ,input_shape=(SIZE2, SIZE, 1)))
fashion_model.add(MaxPooling2D((1, 2), padding = 'same'))
fashion_model.add(Conv2D(32, kernel_size=2, activation='relu', padding="same"))
fashion_model.add(MaxPooling2D((1, 2), padding = 'same'))

fashion_model.add(Conv2D(64, kernel_size=2, activation='relu', padding="same"))
fashion_model.add(MaxPooling2D((1, 2), padding = 'same'))

fashion_model.add(Flatten())

fashion_model.add(Dense(1024, activation='relu'))
fashion_model.add(Dense(N_CLASSES, activation='softmax'))

fashion_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])

fashion_train = fashion_model.fit(X_train, Y_train, epochs=N_EPOCHS, batch_size = BATCH_SIZE,validation_data=(X_valid, Y_valid))
fashion_model.save('/content/drive/MyDrive/Colab Notebooks/model.h5')
     
```
```sh
fashion_model = keras.models.load_model('/content/drive/MyDrive/Colab Notebooks/model.h5')
```
```sh
fashion_model.summary()
```
```sh
#Model Evaluation on the Test Set
import matplotlib.pyplot as plt
accuracy = fashion_train.history['accuracy']
val_accuracy = fashion_train.history['val_accuracy']
loss = fashion_train.history['loss']
val_loss = fashion_train.history['val_loss']
epochs = range(len(accuracy))
plt.plot(epochs, accuracy, 'bo', label='Training accuracy')
plt.plot(epochs, val_accuracy, 'b', label='Validation accuracy')
plt.title('Training and validation accuracy')
plt.legend()
plt.figure()
plt.plot(epochs, loss, 'bo', label='Training loss')
plt.plot(epochs, val_loss, 'b', label='Validation loss')
plt.title('Training and validation loss')
plt.legend()
plt.show()
```
```sh
#Predict Labels
import numpy as np
X_test = X_test.values.reshape(X_test.shape[0], SIZE, SIZE2, 1)
predicted_classes = fashion_model.predict(X_test)
predicted_classes = np.argmax(np.round(predicted_classes),axis=1)
```
## 6. Đánh giá
```sh
from sklearn.metrics import confusion_matrix, accuracy_score
cm = confusion_matrix(Y_test, predicted_classes)
print(cm)
accuracy_score(Y_test, predicted_classes)
```
```sh
#Classification Report
from sklearn.metrics import classification_report
dirs = ['Benign','Adware','Banking','Riskware','SMS']
print(classification_report(Y_test, predicted_classes,target_names=dirs))
```
